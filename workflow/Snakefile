###############################################################################
#  S n a k e m a k e   w o r k f l o w
###############################################################################
import os, glob, pathlib, json, re, multiprocessing as mp, psutil
ENV_YAML  = os.path.join(os.getcwd(), "env", "environment.yml")
configfile: "workflow/config.yaml"

DATASETS  = config["datasets"]
SIG_SIZES = config["sig_sizes"]
RUN_CORES = str(config.get("run_cores", "NA"))       # set by measure.sh

###############################################################################
# helper for the default target ------------------------------------------------
def _inputs_all(wc):
    lst  = expand("results/{ds}/stage1/summary_stage1.tsv", ds=DATASETS)
    lst += expand("results/{ds}/stage1/system_info.json",   ds=DATASETS)
    lst += expand("results/{ds}/stage2/metrics_k{K}.tsv",
                  ds=DATASETS, K=SIG_SIZES)
    for ds in DATASETS:
        lst.append(f"figures/{ds}/runtime/Speed_up.png")
    return lst
rule all: input: _inputs_all
###############################################################################

rule copy_matrix:
    input:  "data/raw/{ds}.csv"
    output: "data/processed/{ds}_matrix.csv"
    conda:  ENV_YAML
    shell:  "cp {input} {output}"

rule stage1_sysinfo:
    output: "results/{ds}/stage1/system_info.json"
    run:
        import platform, time
        out = pathlib.Path(output[0]); out.parent.mkdir(parents=True, exist_ok=True)
        meta = dict(timestamp=time.strftime("%Y‑%m‑%dT%H:%M:%S"),
                    python=platform.python_version(),
                    cores =mp.cpu_count(),
                    ram_GiB=round(psutil.virtual_memory().total/2**30,1),
                    run_cores=RUN_CORES)
        out.write_text(json.dumps(meta, indent=2))

###############################################################################
# -------------------------------  S T A G E 1  -------------------------------
###############################################################################
rule mccv_stage1:
    input:  matrix="data/processed/{ds}_matrix.csv"
    output:
        metrics="results/{ds}/stage1/metrics_k{K}.tsv",
        freq   ="results/{ds}/stage1/freq_k{K}.csv",
        sl_wts ="results/{ds}/stage1/metrics_k{K}.sl_weights.tsv"
    params:
        k="{K}",
        n_splits=config["n_splits"]
    benchmark: "results/{ds}/stage1/wall_clock_k{K}.txt"
    conda: ENV_YAML
    script: "../scripts/python/mccv_stage1.py"
# -----------------------------------------------------------------------------


OUT_TPL = f"results/{{ds}}/stage1/wall_clock_{RUN_CORES}.tsv"
rule record_wall_clock:
    input:
        lambda wc: [f"results/{wc.ds}/stage1/wall_clock_k{k}.txt"
                    for k in SIG_SIZES]
    output: OUT_TPL
    run:
        secs=[]
        for fp in input:
            with open(fp) as fh:
                next(fh, None)
                secs.append(float(next(fh, "0").split("\t")[0]))
        out = pathlib.Path(output[0]); out.parent.mkdir(parents=True, exist_ok=True)
        out.write_text(f"{RUN_CORES}\t{max(secs):.3f}\n")

rule aggregate_stage1:
    input:
        lambda wc: [f"results/{wc.ds}/stage1/metrics_k{k}.tsv"
                    for k in SIG_SIZES]
    output:
        summary="results/{ds}/stage1/summary_stage1.tsv",
        tagged =f"results/{{ds}}/stage1/summary_stage1_{RUN_CORES}.tsv"
    conda: ENV_YAML
    script: "../scripts/python/aggregate_stage1.py"

rule plot_stage1:
    input:
        metrics="results/{ds}/stage1/metrics_k{K}.tsv",
        freq   ="results/{ds}/stage1/freq_k{K}.csv"
    output: directory("figures/{ds}/stage1_k{K}")
    params: title=lambda wc: f"{wc.ds} | K={wc.K}"
    conda:  ENV_YAML
    script: "../scripts/python/plots/plot_stage1.py"

rule plot_stage1_summary:
    input: "results/{ds}/stage1/summary_stage1.tsv"
    output:
        MCE         ="figures/{ds}/stage1_summary/MCE.png",
        Sensitivity ="figures/{ds}/stage1_summary/Sensitivity.png",
        Specificity ="figures/{ds}/stage1_summary/Specificity.png"
    params: title=lambda wc: wc.ds
    conda:  ENV_YAML
    script: "../scripts/python/plots/plot_stage1_summary.py"

###############################################################################
# -------------------------------  S T A G E 2  -------------------------------
###############################################################################
rule stage2_eval:
    input:
        matrix   ="data/processed/{ds}_matrix.csv",
        gene_set ="results/{ds}/stage1/freq_k{K}.csv"
    output: "results/{ds}/stage2/metrics_k{K}.tsv"
    params: k="{K}"
    conda:  ENV_YAML
    script: "../scripts/python/stage2_eval.py"
# -----------------------------------------------------------------------------


###############################################################################
# -------- runtime aggregation / plots  (unchanged except fixed_k removed) ----
###############################################################################
rule merge_wall_clocks:
    input:
        lambda wc: glob.glob(f"results/{wc.ds}/stage1/wall_clock_*.tsv")
    output: "results/{ds}/stage1/runtime_by_cores.tsv"
    run:
        import pandas as pd
        if not input:
            pathlib.Path(output[0]).touch(); return
        rows=[tuple(map(float, pathlib.Path(fp).read_text().split()))
              for fp in input]
        (pd.DataFrame(rows, columns=["cores","wall_clock_s"])
           .drop_duplicates("cores", keep="last")
           .sort_values("cores")
           .to_csv(output[0], sep="\t", index=False))

rule merge_model_runtimes:
    input:
        lambda wc: glob.glob(f"results/{wc.ds}/stage1/summary_stage1_*.tsv")
    output: "results/{ds}/stage1/runtime_by_cores_per_model.tsv"
    run:
        import pandas as pd, re, pathlib
        if not input:
            pathlib.Path(output[0]).touch(); return
        frames=[]
        for fp in input:
            m=re.search(r"summary_stage1_(\d+|NA)\.tsv$", fp)
            cores=int(m.group(1)) if m and m.group(1).isdigit() else -1
            df=pd.read_csv(fp, sep="\t"); df["cores"]=cores; frames.append(df)
        pd.concat(frames).to_csv(output[0], sep="\t", index=False)

rule plot_runtime:
    input:
        stage1_summary = "results/{ds}/stage1/summary_stage1.tsv",
        cores_table    = "results/{ds}/stage1/runtime_by_cores.tsv",
        model_table    = "results/{ds}/stage1/runtime_by_cores_per_model.tsv"
    output:
        Train_mean       = "figures/{ds}/runtime/Train_mean.png",
        Pred_mean        = "figures/{ds}/runtime/Pred_mean.png",
        Train_total      = "figures/{ds}/runtime/Train_total.png",
        Pred_total       = "figures/{ds}/runtime/Pred_total.png",
        Runtime_total    = "figures/{ds}/runtime/Runtime_total.png",
        Speed_up         = "figures/{ds}/runtime/Speed_up.png",
        Wall_clock_vs_cores       = "figures/{ds}/runtime/Wall_clock_vs_cores.png",
        Train_total_vs_cores      = "figures/{ds}/runtime/Train_total_vs_cores.png",
        Pred_total_vs_cores       = "figures/{ds}/runtime/Pred_total_vs_cores.png",
        Train_total_vs_cores_zoom = "figures/{ds}/runtime/Train_total_vs_cores_zoom.png"
    params:
        title = lambda wc: wc.ds
    conda: ENV_YAML
    script: "../scripts/python/plots/plot_runtime.py"
# -----------------------------------------------------------------------------


###############################################################################
# host‑side aggregation – safe from script edits
###############################################################################
rule host_analysis:
    input:
        expand("figures/{ds}/runtime/Speed_up.png", ds=DATASETS)
    output: touch("host_analysis.complete")
    run:
        import subprocess, pathlib
        targets = [
            *expand("results/{ds}/stage1/runtime_by_cores.tsv",           ds=DATASETS),
            *expand("results/{ds}/stage1/runtime_by_cores_per_model.tsv", ds=DATASETS),
            *expand("figures/{ds}/runtime/Speed_up.png",                  ds=DATASETS)
        ]
        subprocess.check_call([
            "snakemake", "-s", "workflow/Snakefile", "--cores", "1",
            "--rerun-triggers", "mtime",   # timestamp only
            *targets
        ])
        pathlib.Path(output[0]).touch()
###############################################################################
